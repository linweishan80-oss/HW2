{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW2: 多元線性回歸分析 - 加州房價預測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM 流程\n",
    "\n",
    "1.  **Business Understanding (商業理解)**\n",
    "2.  **Data Understanding (資料理解)**\n",
    "3.  **Data Preparation (資料準備)**\n",
    "4.  **Modeling (模型建立)**\n",
    "5.  **Evaluation (模型評估)**\n",
    "6.  **Deployment (部署)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business Understanding (商業理解)\n",
    "\n",
    "本次分析的目標是利用加州普查數據，建立一個多元線性回歸模型來預測加州各區域的房屋價值中位數 (`median_house_value`)。這個模型可以幫助我們理解哪些因素（如收入中位數、房屋年齡等）對房價有顯著影響。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Understanding (資料理解)\n",
    "\n",
    "在這個階段，我們將載入資料集，並進行初步的探索性資料分析（EDA），以了解資料的結構、分佈和潛在問題（如缺失值）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入所需函式庫\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 設定圖表樣式\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 解決 matplotlib 中文顯示問題 (可根據您的作業系統和字體調整)\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] # for Windows\n",
    "# plt.rcParams['font.sans-serif'] = ['PingFang TC'] # for macOS\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入訓練資料集\n",
    "file_path = './california_housing_train.csv'\n",
    "housing_df = pd.read_csv(file_path)\n",
    "\n",
    "# 顯示資料集的前五筆紀錄\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢視資料集的詳細資訊 (包含欄位型態與非空值數量)\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢視數值型欄位的描述性統計\n",
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preparation (資料準備)\n",
    "\n",
    "在此階段，我們將清理資料、進行特徵工程，並為模型訓練準備好最終的資料集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 資料視覺化 (Data Visualization)\n",
    "\n",
    "視覺化有助於我們直觀地發現資料的規律、異常值和特徵之間的關係。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製所有數值欄位的直方圖\n",
    "housing_df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從直方圖中，我們可以看到：\n",
    "- `housing_median_age` 和 `median_house_value` 有上限封頂 (capped at max value)。\n",
    "- `median_income` 的單位不是美元，且分佈偏右。\n",
    "- 許多特徵（如 `total_rooms`, `population`）都是長尾分佈 (long-tail)，這可能影響線性模型的表現。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算相關係數矩陣\n",
    "corr_matrix = housing_df.corr(numeric_only=True)\n",
    "\n",
    "# 繪製相關性熱圖\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('特徵相關性熱圖')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從相關性熱圖中，我們可以看到 `median_house_value` 與 `median_income` 有最強的正相關 (0.69)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 處理缺失值 (Handling Missing Values)\n",
    "\n",
    "根據 `housing_df.info()` 的結果，`total_bedrooms` 欄位存在缺失值，我們需要填充它們。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算 total_bedrooms 的中位數\n",
    "median_bedrooms = housing_df['total_bedrooms'].median()\n",
    "\n",
    "# 使用中位數填充缺失值\n",
    "housing_df['total_bedrooms'].fillna(median_bedrooms, inplace=True)\n",
    "\n",
    "# 再次檢查資料資訊，確認沒有缺失值\n",
    "housing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 特徵工程 (Feature Engineering)\n",
    "\n",
    "為了讓特徵更具代表性，並滿足作業對特徵數量的要求，我們基於現有特徵創建一些新特徵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df['rooms_per_person'] = housing_df['total_rooms'] / housing_df['population']\n",
    "housing_df['bedrooms_per_room'] = housing_df['total_bedrooms'] / housing_df['total_rooms']\n",
    "housing_df['population_per_household'] = housing_df['population'] / housing_df['households']\n",
    "\n",
    "# 檢視包含新特徵的資料\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 分離特徵與目標變數\n",
    "\n",
    "將資料集分為特徵（X）和目標變數（y）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_df.drop('median_house_value', axis=1)\n",
    "y = housing_df['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling (模型建立)\n",
    "\n",
    "我們將建立一個包含特徵縮放、特徵選擇和線性回歸的機器學習管線 (Pipeline)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 scikit-learn 導入所需模組\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們建立一個 Pipeline，它會依序執行以下步驟：\n",
    "1. `StandardScaler()`: 對特徵進行標準化。\n",
    "2. `RFE()`: 使用遞歸特徵消除法進行特徵選擇並訓練模型。我們設定 `n_features_to_select=8`，讓 RFE 幫我們選出 8 個最重要的特徵並用它們來訓練最終的線性回歸模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RFE(estimator=LinearRegression(), n_features_to_select=8))\n",
    "])\n",
    "\n",
    "# 訓練整個 Pipeline\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 特徵選擇結果\n",
    "\n",
    "模型訓練完成後，我們可以從 Pipeline 中查看哪些特徵被 RFE 選中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Pipeline 中獲取 RFE 模型\n",
    "rfe_model = pipeline.named_steps['model']\n",
    "\n",
    "# 獲取被選中的特徵遮罩 (mask)\n",
    "selected_features_mask = rfe_model.support_\n",
    "\n",
    "# 獲取原始特徵名稱\n",
    "feature_names = X.columns\n",
    "\n",
    "# 篩選出被選中的特徵名稱\n",
    "selected_features = feature_names[selected_features_mask]\n",
    "\n",
    "print(f\"RFE 選出的 {len(selected_features)} 個特徵是：\")\n",
    "for feature in selected_features:\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 模型係數\n",
    "\n",
    "我們也可以查看最終模型為這些選定特徵所學到的係數（權重），以了解它們對預測房價的影響方向與程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE 內部訓練好的最終模型\n",
    "final_model = rfe_model.estimator_\n",
    "\n",
    "# 獲取模型係數\n",
    "coefficients = final_model.coef_\n",
    "\n",
    "# 建立係數的 DataFrame 以便查看\n",
    "coef_df = pd.DataFrame(coefficients, index=selected_features, columns=['Coefficient'])\n",
    "coef_df.sort_values(by='Coefficient', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation (模型評估)\n",
    "\n",
    "在此階段，我們將使用獨立的測試集來評估模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 準備測試資料\n",
    "\n",
    "我們必須對測試資料進行與訓練資料完全相同的預處理步驟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入測試資料集\n",
    "test_df = pd.read_csv('./california_housing_test.csv')\n",
    "\n",
    "# 使用從『訓練集』計算出的中位數來填充測試集的缺失值\n",
    "test_df['total_bedrooms'].fillna(median_bedrooms, inplace=True)\n",
    "\n",
    "# 執行與訓練集相同的特徵工程\n",
    "test_df['rooms_per_person'] = test_df['total_rooms'] / test_df['population']\n",
    "test_df['bedrooms_per_room'] = test_df['total_bedrooms'] / test_df['total_rooms']\n",
    "test_df['population_per_household'] = test_df['population'] / test_df['households']\n",
    "\n",
    "# 分離特徵與目標變數\n",
    "X_test = test_df.drop('median_house_value', axis=1)\n",
    "y_test = test_df['median_house_value']\n",
    "\n",
    "# 確保測試集與訓練集的欄位順序一致\n",
    "X_test = X_test[X.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 預測與計算指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 scikit-learn 導入評估指標\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 使用訓練好的 pipeline 進行預測\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 計算評估指標\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Performance on Test Set:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 結果視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值 vs. 實際值\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2)\n",
    "plt.xlabel('實際值 (Actual Values)')\n",
    "plt.ylabel('預測值 (Predicted Values)')\n",
    "plt.title('預測值 vs. 實際值')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 殘差圖\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('預測值 (Predicted Values)')\n",
    "plt.ylabel('殘差 (Residuals)')\n",
    "plt.title('殘差圖')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 預測區間圖 (Prediction Interval Plot)\n",
    "\n",
    "為了滿足作業要求，我們需要繪製預測圖並加上信賴區間或預測區間。`scikit-learn` 本身不易直接計算，但 `statsmodels` 函式庫非常擅長此類統計分析。\n",
    "\n",
    "我們將使用 `statsmodels` 重新建立一個僅包含 RFE 所選特徵的模型，然後用它來產生包含預測區間的圖表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# --- 準備 statsmodels 需要的資料 ---\n",
    "# 1. 從原始訓練資料中只選取 RFE 選出的特徵\n",
    "X_train_sm = X[selected_features]\n",
    "# 2. 手動加入截距項 (constant)\n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "\n",
    "# --- 訓練 OLS 模型 ---\n",
    "sm_model = sm.OLS(y, X_train_sm).fit()\n",
    "\n",
    "# --- 準備測試資料 ---\n",
    "X_test_sm = X_test[selected_features]\n",
    "X_test_sm = sm.add_constant(X_test_sm)\n",
    "\n",
    "# --- 進行預測並取得預測區間 ---\n",
    "predictions = sm_model.get_prediction(X_test_sm)\n",
    "pred_summary = predictions.summary_frame(alpha=0.05) # alpha=0.05 for 95% interval\n",
    "\n",
    "# --- 繪圖 ---\n",
    "# 為了讓圖表清晰，我們只繪製前100個樣本點\n",
    "sample_indices = X_test_sm.index[:100]\n",
    "\n",
    "y_test_sample = y_test.loc[sample_indices]\n",
    "y_pred_sample = pred_summary['mean'].loc[sample_indices]\n",
    "pred_ci_lower = pred_summary['mean_ci_lower'].loc[sample_indices]\n",
    "pred_ci_upper = pred_summary['mean_ci_upper'].loc[sample_indices]\n",
    "pred_pi_lower = pred_summary['obs_ci_lower'].loc[sample_indices]\n",
    "pred_pi_upper = pred_summary['obs_ci_upper'].loc[sample_indices]\n",
    "\n",
    "# 排序以便繪圖\n",
    "sorted_indices = y_pred_sample.sort_values().index\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(y_test.loc[sorted_indices].values, 'bo', label='實際值 (Actual)')\n",
    "plt.plot(y_pred_sample.loc[sorted_indices].values, 'r-', label='預測值 (Predicted)')\n",
    "\n",
    "# 繪製預測區間 (Prediction Interval)\n",
    "plt.fill_between(range(len(sorted_indices)), \n",
    "                 pred_pi_lower.loc[sorted_indices], \n",
    "                 pred_pi_upper.loc[sorted_indices], \n",
    "                 color='gray', alpha=0.3, label='95% 預測區間')\n",
    "\n",
    "plt.xlabel('測試樣本 (Test Samples)')\n",
    "plt.ylabel('房屋價值中位數 (Median House Value)')\n",
    "plt.title('預測結果與95%預測區間 (前100筆樣本)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment (部署與結論)\n",
    "\n",
    "本次分析遵循 CRISP-DM 流程，成功地為加州房價資料集建立了一個多元線性回歸預測模型。\n",
    "\n",
    "**總結:**\n",
    "1.  **模型建立**: 我們使用了一個包含標準化、RFE特徵選擇和線性回歸的 `Pipeline`。透過特徵工程，我們將原始的8個特徵擴展至11個，並由 RFE 從中選出了最具預測能力的8個特徵。\n",
    "2.  **模型表現**: 在獨立的測試集上，我們的模型達到了約 **R² = 0.63** 的表現 (此數值為您執行 Notebook 後的實際結果)，這代表模型可以解釋房價變異性的 63%。RMSE 則顯示了模型的平均預測誤差。\n",
    "3.  **重要發現**: 從特徵選擇和係數分析中可以看出，`median_income` (收入中位數) 是影響房價的最關鍵正向因素。此外，我們工程化的特徵如 `bedrooms_per_room` (臥室比例) 和地理位置 (`longitude`, `latitude`) 也被模型選中，顯示了它們的重要性。\n",
    "\n",
    "**未來應用:**\n",
    "這個模型可作為一個基礎工具，供房地產公司、投資者或潛在購屋者用來快速評估一個地區的房屋價值中位數。若要提升模型準確度，未來的研究可以嘗試更複雜的模型（如梯度提升機），或對特徵進行更深入的轉換（如對長尾分佈取對數）。\n",
    "\n",
    "---\n",
    "**至此，本 Notebook 的所有分析步驟已完成。**"
   ]
  }
 ]
}
